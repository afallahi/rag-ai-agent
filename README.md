# RAG PDF Agent

This project builds a Retrieval-Augmented Generation (RAG) system. It is developed in a **test-driven way**, where each step includes both functionality and verification via unit tests.



## Project Goals

- Parse and extract text from PDFs
- Chunk and embed the text
- Store embeddings in a vector database (FAISS)
- Use a local LLM for question-answering (RAG pipeline)
- Validate every stage with automated tests



## Project Structure

```
rag-project/
â”œâ”€â”€ .venv/
â”œâ”€â”€ sample_pdfs/
â”œâ”€â”€ main.py
â”œâ”€â”€ main/
â”‚ â””â”€â”€ extractor.py
â”‚   â””â”€â”€ pdf_extractor.py # Step 1: PDF extraction
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ test_pdf_extractor.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Setup

### 1. Create virtual environment

Run `python -m venv .venv`

### 2. 2. Activate environment


Run `.\.venv\Scripts\activate`

### 3. Install requirements

`pip install -r requirements.txt`


## Steps

| Step | Description                         | Status         |
| ---- | ----------------------------------- | -------------- |
| 1    | PDF Text Extraction (PyMuPDF)       | ğŸ”„ In Progress |
| 2    | Text Chunking                       | â³ Pending      |
| 3    | Embedding with SentenceTransformers | â³ Pending      |
| 4    | Vector Store Setup (FAISS)          | â³ Pending      |
| 5    | LLM Integration (Ollama, llama-cpp) | â³ Pending      |
| 6    | Full RAG Pipeline                   | â³ Pending      |


## Running Tests

`pytest`

## Tools Used

- PyMuPDF for PDF parsing
- LangChain for chunking logic
- Sentence Transformers for embedding
- FAISS for vector search
- Local LLMs (via Ollama or llama-cpp)
